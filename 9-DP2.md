## DP 2

#### Matching DNA sequences

Para comparar cadenas de ADN se utilizan 3 problemas:

1. La subpalabra más larga en común: 

Subpalabra = carácteres consecutivos en una palabra

2. La subsecuencia más larga en común:

Subsecuencia = cadena ordenada de carácteres

3. Distancia de edición: 

Convertir una palabra en otra utilizando un conjunto dado de operaciones

Se define como el número mínimo de operaciones para transformar X en Y

Todas las operaciones se aplican sobre X

*Distancia Levenshtein*:

Conjunto de operaciones

1) insert(X,i,a), coste 1 
2) delete(X,i), coste 1
3) modify(X,i,a), coste 2


**Distancia de edición, recurrencia:**

Sea X[i] = x1...xi
Sea Y[j] = y1...yj

E[i,j] la distancia de edición de X[i] a Y[j] el máximo de:

    - I poner yj al final de x: E[i, j-1] +1
    - D eliminar xi: E[i-1, j] +1
    - Si xi /= yj, M cambio de xi a yj: E [i − 1, j − 1] + 1,
      sino E [i − 1, j − 1]
      
Añadiendo los casos base:
    
    E[i, j]:
        j si i = 0 (convertir λ → Y[j])
        i si j = 0 (convertir X[i] → λ)
        
        min:
            E[i-1, j] + 1 si D
            E[i, j-1] + 1 si I
            E[i-1, j-1] + 1 si M
            
    donde 
    
        δ(xi , yj) = 0 si xi = yj 
                   = 1 sino
                   
**Subsecuencia más larga común:**

TTT es una subsecuencia de ATATAT

Si Z es una subsecuencia de X e Y entonces Z es una subsecuencia común de X e Y.

LGS, dada una secuencia X = x1...xn y Y = y1 ...  ym, encontrar Z

- Z = xi1...xik = yj1...yjk
- No hay i, j las cuales i > ik y j > jk tales que xi = yj, sino Z no seria óptima
- a = xik debe aparecer antes de ik en X, pero no después de jk en Y o viceversa
- Hay una solución óptima en la cual ik y jk son la última ocurrencia de a en X e Y respectivamente


Sea X- = x1...xn-1 y Y- = y1...ym-1

    Si xn /= ym
        Si ik < n y ik < m, Z es un lcs de X- e Y-
        Si ik = n y jk < m, Z es un lcs de X e Y-
        Si ik < n y jk = m, Z es un lcs de X- e Y
        
Subproblemas = lcs de pares de prefijos de las palabras iniciales. 

*Notación:*

- X[i] = x1...xi, para 0 <= i <= n
- Y[j] = y1...yj, para 0 <= j <= m
- c[i,j] = longitud del lcs de X[i] e Y[j]
- Queremos c[n,m], por ejemplo la longitud del lcs para X e Y

Tenemos entonces, dados una X y una Y:

    c[i, j]:
        0 si i = 0 o j = 0
        c[i-1, j-1] + 1 si xi = yj
        max(c[i, j-1], c[i-1, j]) sino
        
Si implementaramos esto recursivamente tendríamos 1 o 2 llamadas recursivas que exploran un árbol de profundidad O(n+m), por tanto, la complejidad temporar es de 2^O(n+m)

Si recorremos los valores por filas:

    LCS(X , Y):
        for i = 0 to n do
            c[i, 0] = 0
        for j = 1 to m do
            c[0, j] = 0
        for i = 1 to n do
            for j = 1 to m do
                if xi = yj then
                    c[i, j] = c[i − 1, j − 1] + 1, b[i.j] =↖
                else if c[i − 1, j] ≥ c[i, j − 1] then
                    c[i, j] = c[i − 1, j], b[i, j] =←
                else
                    c[i, j] = c[i, j − 1], b[i, j] =↑
                    
Complejidad = O(n*m)

**Subpalabra más larga común:**

Un problema un poco diferente con una solución similar

Por ejemplo, si X = DEADBBEEF e Y = EATBEEF, Z = BEEF

Sea X = x1...xn e Y = y1...ym y Z la subpalabra más larga en común:
    
    Z = xi...xi+k = yj...yj+k
    Z es el sufijo más largo común de X(i+k) e Y(j+k)

Podemos considerar los subproblemas LCStf(i,j): computar el sufijo más largo de X(i) e Y(j)

El LCSf(X,Y) es el más largo de todos los sufijos

Para resolver el problema es suficiente hacer i-1 en X y j-1 en Y hasta encontrar dos carácteres diferentes

El coste es O(n+m) por subproblema. 
En total: O(n*m(n+m)) para LCSt

**Se puede hacer más rápido**

*Notación:*

- X[i] = x1...xi para 0 <= i <= n
- Y[j] = y1...yj para 0 <= j <= m
- s[i,j] = longitud del sufijo LC de X[i] e Y[j]
- Queremos max i,j,s[i,j], la longitud del LCSt de X e Y.

Dados X e Y:
    
    s[i,j] 
        0 si i = 0 o j = 0
        0 si xi /= yj
        s[i-1,j-1] + 1 si xi = yj
        
Utilizando la recurrencia, el coste es constante por llamada recursiva

*Código:*
    
    LCSf(X,Y):
        for i = 0 to n do:
            s[i,0] = 0
        for j = 1 to m do:
            s[0,j] = 0
        for i = 1 to n do:
            for j = 1 to m do:
                s[i,j] = 0
                if xi = yj then
                    s[i,j] = s[i-1,j-1] + 1

Complejidad temporal: O(n*m)

#### Multiplicando una secuencia de matrices

Dadas una secuencia de n matrices (A1xA2x...xAn), minimizar el número de operaciones para la computación de la multiplicación de todas ellas. 

A tener en cuenta:

- La multiplicación de matrices **NO** es comutativa, por lo que no podemos permutar el orden de las matrices sin cambiar el resultado. 
- Es asociativa, por lo que podemos poner los paréntesis que queramos. 
- Como multiplicar las matrices es quivalente al problema de como palentizarlas.
- Queremos encontrar los paréntesis que hagan que su multiplicación requiera el mínimo número total de operaciones y utilizarlo para computar la multiplicación. 

*Ejemplo inicial:*

Sea la dimensión (A1) = 10 x 100

Sea la dimensión (A2) = 100 x 5

Sea la dimensión (A3) = 5 x 50

- ((A1A2)A3) requiere: (10x100x5) + (10x5x50) = 7500 operaciones
- (A1(A2A3)) requiere: (100x5x50) + (10x100x50) = 75000 operaciones

**El orden importa**

Sea P(n) el número de formas de palentizar (A1x..xAn), entonces:
    
    P(n):
        1 si n = 1
        Σ desde k = 1 hasta n-1 P(k)*P(n-k) si n>=2
        
Con solución: Ω(4^n/n^(3/2)) (los números catalanes)

Descartamos la opción de fuerza bruta (backtracking)

- Queremos computar (A1x...xAn) eficientemente. 
- El coste(A1...An) = coste(A1...Ak) + coste(Ak+1...An) + p0 * pk * pn

Sea m[i,j] el mínimo coste de cómputo

    Bij = (Ai x ... x Aj) para 1 <= i <= j <= n
    m[i,j] se define por el valor de k, i <= k <= j que minimiza:
        m[i,k] + m[k + 1, j] + coste (Bik, Bk+1,j)
    
*La recurrencia*

    m[i,j] 
        0 si i = j
        min {m[i, k] + m[k+1, j] + pi-1 * pk * pj} para i <= k < j sino

El coste es 2^n (exponencial)

El número de subproblemas es n², identificados por i y j 

Podemos sacar partido de la programación dinámica:
T (n) = Θ(n³) y espacio adicional Θ(n²)

#### Programación dinámica en árboles

Los árboles son grafos fácilmente adaptables a la recursión. 

En estos casos, podemos aprovechar la estructura del árbol para guardar información extra en cada nodo sin necesidad de construir una tabla. 

**The maximum weight independent set**

Dado un grafo G = (V,E) con pesos pertenencientes a los reales, encontrar el más pesado S ⊆ V  tal que dos verticces de S no están conectados. 

Para grafos, el problema es NP-Completo

*Notación:*

- Para v ∈ V, Tv subárbol con ráiz v . T = Tr. 
- Dado v ∈ V, C(v) será el conjunto de hijos de v y G(V) será el conjunto de nietos de v. 

La solución no contendrá vértices de padres e hijos. 

- Si r ∈ S: entonces C(r) /∈ Sr. S - {r} contiene una solución óptima para cada Tv con v ∈ G(r)
- SI r /∈ S: entonces S contiene una solución óptima para cada Tu, con u ∈ C(r)

*Recurrencia:*

    w(v) v es una hoja
    max(Σ de las u ∈ C(v), w(v) + Σ de las u ∈ G(v)) sino
